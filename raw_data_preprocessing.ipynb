{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**vk**"
      ],
      "metadata": {
        "id": "bPEuPi1LzpiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import json\n",
        "import chardet"
      ],
      "metadata": {
        "id": "TX7bJSS5xA5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def extract_comments_from_file(input_file, output_file):\n",
        "    try:\n",
        "        # Чтение файла построчно\n",
        "        with open(input_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            file_content = f.read()\n",
        "\n",
        "        # Регулярное выражение для извлечения содержимого <text>, где comment=\"Y\"\n",
        "        text_blocks = re.findall(r'<text[^>]*comment=\"Y\"[^>]*>(.*?)</text>', file_content, re.DOTALL)\n",
        "\n",
        "        # Очистка от HTML-тегов и подготовка данных\n",
        "        cleaned_data = []\n",
        "        for idx, block in enumerate(text_blocks, 1):\n",
        "            clean_text = re.sub(r'<br\\s*/?>', '\\n', block)  # Заменяем <br /> на переносы строки\n",
        "            clean_text = re.sub(r'<.*?>', '', clean_text)  # Удаляем оставшиеся HTML-теги\n",
        "            clean_text = re.sub(r'\\s+', ' ', clean_text).strip()  # Удаляем лишние пробелы\n",
        "            cleaned_data.append({\"index\": idx, \"text\": clean_text})\n",
        "\n",
        "        # Сохранение в JSON\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(cleaned_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "        print(f\"Комментарии с comment='Y' успешно сохранены в {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Ошибка: файл {input_file} не найден.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Произошла ошибка: {e}\")"
      ],
      "metadata": {
        "id": "5EA-7msDjJkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к исходному файлу и выходному файлу\n",
        "input_file = 'INPUT_FILE_PATH'\n",
        "output_file = 'OUTPUT_FILE_PATH'"
      ],
      "metadata": {
        "id": "_vBfoDn9zRVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_comments_from_file(input_file, output_file)"
      ],
      "metadata": {
        "id": "nfx9644FxSV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "\n",
        "# Путь к папке с JSON-файлами\n",
        "json_files = glob.glob(\"/content/*.json\")\n",
        "\n",
        "combined_data = []\n",
        "for file in json_files:\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "        combined_data.extend(data)\n",
        "\n",
        "# Сохранение объединенного файла\n",
        "with open(\"combined.json\", \"w\", encoding=\"utf-8\") as outfile:\n",
        "    json.dump(combined_data, outfile, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Подсчет количества текстов\n",
        "print(f\"Общее количество текстов: {len(combined_data)}\")"
      ],
      "metadata": {
        "id": "UIdqPhsd7n3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Открываем объединённый JSON-файл\n",
        "with open(\"combined.json\", \"r\", encoding=\"utf-8\") as infile:\n",
        "    combined_data = json.load(infile)\n",
        "\n",
        "# Определяем размер каждого файла\n",
        "chunk_size = 200\n",
        "total_chunks = len(combined_data) // chunk_size + (1 if len(combined_data) % chunk_size != 0 else 0)\n",
        "\n",
        "# Создаём папку для выходных файлов, если ее еще нет\n",
        "output_dir = \"/content/outputss\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i in range(total_chunks):\n",
        "    # Получаем часть данных\n",
        "    chunk_data = combined_data[i * chunk_size:(i + 1) * chunk_size]\n",
        "\n",
        "    # Формируем имя файла\n",
        "    file_name = f\"vk_{(i + 1) * chunk_size}.json\"\n",
        "    file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "    # Сохраняем данные в отдельный файл\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "        json.dump(chunk_data, outfile, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Всего создано файлов: {total_chunks}\")"
      ],
      "metadata": {
        "id": "IA5dfV5e8rVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('/content/outputss_archive', 'zip', '/content/outputss')\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/outputss_archive.zip')"
      ],
      "metadata": {
        "id": "36uL04_N856d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}