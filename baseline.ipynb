{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF**\n"
      ],
      "metadata": {
        "id": "XJrOLr8_LTKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "VEyVlfwXEUFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHl-7qtk6G9G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка датасета\n",
        "df = pd.read_csv('PATH_TO_DATASET')"
      ],
      "metadata": {
        "id": "4U_m5MpcBjIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "JR_I1UhHBmBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на признаки и целевую переменную\n",
        "X = df['utterance']  # Тексты\n",
        "y = df['label']      # Метки"
      ],
      "metadata": {
        "id": "UHG8CvcwBw4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Векторизация текстов с помощью TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Ограничим количество признаков для простоты\n",
        "X_vectorized = vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "AAAXlKe5Fqxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Wsndz1Y_FTz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение логистической регрессии с увеличенным class_weight для эвфемизмов\n",
        "model = LogisticRegression(class_weight={0: 1, 1: 20}, random_state=42)  # Вес 20 для класса 1\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "mMgJNuJfEym5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "4NUuuhj3GA2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1-score для класса 1 (эвфемизмы)\n",
        "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "print(f\"F1-score для класса 1 (эвфемизмы): {f1:.2f}\")"
      ],
      "metadata": {
        "id": "8uiMTFdwGDWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка модели\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "CJvmhZUjGK9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем уменьшить количество текстов с меткой 0, чтобы сбалансировать датасет, и используем все тексты с меткой 1**"
      ],
      "metadata": {
        "id": "FUFg7xxmLc1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение датасета на тексты с меткой 0 и 1\n",
        "df_label_0 = df[df['label'] == 0]  # Тексты с меткой 0\n",
        "df_label_1 = df[df['label'] == 1]  # Тексты с меткой 1"
      ],
      "metadata": {
        "id": "_UossKRWPhtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_label_0)"
      ],
      "metadata": {
        "id": "7tTFuPGsQreH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_label_1)"
      ],
      "metadata": {
        "id": "tG4uc9myQtpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Уменьшение количества текстов с меткой 0\n",
        "# Текстов с 0 возьмем в 8 раз больше, чем с 1\n",
        "num_samples = len(df_label_1)  # Количество текстов с меткой 1\n",
        "df_label_0_sampled = df_label_0.sample(n=num_samples*9, random_state=42)  # Выборка текстов с меткой 0"
      ],
      "metadata": {
        "id": "ybYGXIS0PnN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание сбалансированного датасета\n",
        "balanced_df = pd.concat([df_label_0_sampled, df_label_1], ignore_index=True)"
      ],
      "metadata": {
        "id": "syrzTxNqP1Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка баланса классов\n",
        "print(\"Распределение классов в сбалансированном датасете:\")\n",
        "print(balanced_df['label'].value_counts())"
      ],
      "metadata": {
        "id": "5u3t27e6P3ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Векторизация текстов с помощью TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Ограничиваем количество признаков\n",
        "X = vectorizer.fit_transform(balanced_df['utterance'])\n",
        "y = balanced_df['label']\n",
        "texts = balanced_df['utterance']  # Добавим тексты отдельно, чтобы позже использовать их для ручного анализа"
      ],
      "metadata": {
        "id": "EHizB-b4P8Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на обучающую и тестовую выборки\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, balanced_df['label'], test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test, texts_train, texts_test = train_test_split(\n",
        "    X, y, texts, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "xx4o77XSP9dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение логистической регрессии\n",
        "# Увеличиваем вес для редкого класса (эвфемизмы) до 5\n",
        "model = LogisticRegression(class_weight={0: 1, 1: 5}, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "q0S_Z2z-QEOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "-mi-HDICQJPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка модели\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "YNq2F8esQLA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1-score для класса 1 (эвфемизмы)\n",
        "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "print(f\"F1-score для класса 1 (эвфемизмы): {f1:.2f}\")"
      ],
      "metadata": {
        "id": "DYdyoT4RQNm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1-score для класса 0 (не-эвфемизмы)\n",
        "f1 = f1_score(y_test, y_pred, pos_label=0)\n",
        "print(f\"F1-score для класса 0 (не-эвфемизмы): {f1:.2f}\")"
      ],
      "metadata": {
        "id": "of7NSpT2QjRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class weight = 20\n",
        "\n",
        "# если брать текстов с 0 в 7 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.42\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.83\n",
        "\n",
        "# если брать текстов с 0 в 8 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.42\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.86\n",
        "\n",
        "# если брать текстов с 0 в 9 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.39\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.87\n",
        "\n",
        "# если брать текстов с 0 в 10 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.36\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.89\n",
        "\n",
        "# если брать текстов с 0 в 15 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.30\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.92\n",
        "\n",
        "# если брать текстов с 0 в 20 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.29\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.94"
      ],
      "metadata": {
        "id": "wN2aqdfaTug1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class weight = 15\n",
        "\n",
        "# если брать текстов с 0 в 8 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.44\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.88\n",
        "\n",
        "# если брать текстов с 0 в 9 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.40\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.88"
      ],
      "metadata": {
        "id": "skBqG2yzZNtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class weight = 10\n",
        "\n",
        "# если брать текстов с 0 в 8 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.45\n",
        "# F1-score для класса 1 0 (не-эвфемизмы): 0.90\n",
        "\n",
        "# если брать текстов с 0 в 9 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.42\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.90"
      ],
      "metadata": {
        "id": "El8mS7gCZcpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class weight = 5\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# если брать текстов с 0 в 8 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.45\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.92                                                          ю\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# если брать текстов с 0 в 9 раз больше, чем с 1, то :\n",
        "# F1-score для класса 1 (эвфемизмы): 0.44\n",
        "# F1-score для класса 0 (не-эвфемизмы): 0.93"
      ],
      "metadata": {
        "id": "F09Npx94Zl8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохраним предсказания для ручного анализа\n",
        "\n",
        "# Предсказания\n",
        "y_pred = model.predict(X_test)\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Оценка\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "f1_class_1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "f1_class_0 = f1_score(y_test, y_pred, pos_label=0)\n",
        "print(f\"F1-score для класса 1 (эвфемизмы): {f1_class_1:.2f}\")\n",
        "print(f\"F1-score для класса 0 (не-эвфемизмы): {f1_class_0:.2f}\")\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'utterance': texts_test.values,\n",
        "    'true_label': y_test.values,\n",
        "    'predicted_label': y_pred,\n",
        "    'predicted_prob': y_probs\n",
        "})\n",
        "\n",
        "# Ошибки модели\n",
        "fp = results_df[(results_df['true_label'] == 0) & (results_df['predicted_label'] == 1)]\n",
        "fn = results_df[(results_df['true_label'] == 1) & (results_df['predicted_label'] == 0)]\n",
        "errors = pd.concat([fp, fn]).sample(n=min(50, len(fp) + len(fn)), random_state=42)\n",
        "\n",
        "# Сомнительные предсказания (уверенность между 0.4 и 0.6)\n",
        "uncertain = results_df[\n",
        "    (results_df['predicted_prob'] > 0.4) & (results_df['predicted_prob'] < 0.6)\n",
        "].sample(n=min(30, len(results_df)), random_state=42)\n",
        "\n",
        "# True Positives\n",
        "tp = results_df[\n",
        "    (results_df['true_label'] == 1) & (results_df['predicted_label'] == 1)\n",
        "].sample(n=min(20, len(results_df)), random_state=42)\n",
        "\n",
        "# Объединение всех примеров в один датафрейм\n",
        "final_sample = pd.concat([errors, uncertain, tp]).sample(frac=1, random_state=42)  # перемешаем\n",
        "\n",
        "final_sample.to_csv(\"baseline_predictions_to_manual_check.csv\", index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "pdvH5VUWhmPX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}