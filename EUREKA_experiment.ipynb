{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Px41zuHC3tJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjAIaDYI0waa"
      },
      "outputs": [],
      "source": [
        "# Загрузка датасета\n",
        "df = pd.read_csv('PATH_TO_DATASET')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение датасета на тексты с меткой 0 и 1\n",
        "df_label_0 = df[df['label'] == 0]  # Тексты с меткой 0\n",
        "df_label_1 = df[df['label'] == 1]  # Тексты с меткой 1"
      ],
      "metadata": {
        "id": "DpzFb3Sh3J78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Уменьшение количества текстов с меткой 0\n",
        "# Текстов с 0 возьмем в столько же, сколько с 1\n",
        "# У авторов EUREKA вообще 0 в два раза меньше, чем 1\n",
        "num_samples = len(df_label_1)  # Количество текстов с меткой 1\n",
        "df_label_0_sampled = df_label_0.sample(n=num_samples*1, random_state=42)  # Выборка текстов с меткой 0"
      ],
      "metadata": {
        "id": "MKZNjYlP3TGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание сбалансированного датасета\n",
        "balanced_df = pd.concat([df_label_0_sampled, df_label_1], ignore_index=True)"
      ],
      "metadata": {
        "id": "VFojpRkx3T3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка баланса классов\n",
        "print(\"Распределение классов в сбалансированном датасете:\")\n",
        "print(balanced_df['label'].value_counts())"
      ],
      "metadata": {
        "id": "H6Swp7hC3T8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение на обучающую и тестовую выборки\n",
        "train_df, test_df = train_test_split(balanced_df, test_size=0.2, stratify=balanced_df['label'], random_state=42)"
      ],
      "metadata": {
        "id": "pDGQN_pw3caO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df))\n",
        "print(len(test_df))"
      ],
      "metadata": {
        "id": "IbFpjuJZ3ifM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J65wihYNIjMH"
      },
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "!pip install -r https://raw.githubusercontent.com/sedrickkeh/EUREKA/main/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRzATY_t-25U"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/sedrickkeh/EUREKA.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_train_df = pd.read_csv('/content/EUREKA/data/train_split.csv')\n",
        "eng_test_df = pd.read_csv('/content/EUREKA/data/test_split.csv')"
      ],
      "metadata": {
        "id": "pptBwR7RvrgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_test_df"
      ],
      "metadata": {
        "id": "ngRQGIf1v7AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_train_df"
      ],
      "metadata": {
        "id": "OFTmcqPq6bB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавим наши test_df и train_df\n",
        "\n",
        "combined_train_df = pd.concat([eng_train_df, train_df], ignore_index=True)\n",
        "combined_test_df = pd.concat([eng_test_df, test_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "TXl0Kg_ev-1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_test_df"
      ],
      "metadata": {
        "id": "-kRHxMQiwfuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train_df"
      ],
      "metadata": {
        "id": "WZFh4Tb96n5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохраним новые версии датасетов (англ+русск)\n",
        "\n",
        "combined_train_df.to_csv('/content/EUREKA/data/train_split.csv')\n",
        "combined_test_df.to_csv('/content/EUREKA/data/test_split.csv')"
      ],
      "metadata": {
        "id": "2H-32X5Bw9qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers==4.3.0\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "GzmSCYun6_8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_0S4wzf_SSf"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "!python /content/EUREKA/train.py --train_path /content/EUREKA/data/train_split.csv \\\n",
        "                --valid_path /content/EUREKA/data/dev_split.csv \\\n",
        "                --test_path /content/EUREKA/data/test_split.csv \\\n",
        "                --cleaning_path /content/EUREKA/data/candidate_replacements.csv\\\n",
        "                --augmentation_path /content/EUREKA/data/augmentation_substitution_wikimatrix.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/EUREKA/train.py --train_file /content/EUREKA/data/train_split.csv --eval_file /content/EUREKA/data/dev_split.csv --output_dir /content/EUREKA/output"
      ],
      "metadata": {
        "id": "LvSsgzX4TjwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EhjOOr0rBnh"
      },
      "outputs": [],
      "source": [
        "# Download tokenizer\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
        "model_checkpoint = \"FacebookAI/xlm-roberta-large\"\n",
        "\n",
        "# Load the best model\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained('/content/EUREKA/output/checkpoint-500')\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkVMQi6ENYps"
      },
      "outputs": [],
      "source": [
        "# # Use the best model\n",
        "# sentences = [\n",
        "#     \"She suddenly passed away yesterday. It is so sad.\",\n",
        "#     \"I'd give it 50-50, especially if senior members of the regime die from the disease.\",\n",
        "#     \"Norman Cook (aka Fatboy Slim) is back with his latest project The Brighton Port Authority, or The BPA. The liner notes give a funny, fictional account about the music on this disc and how it came to pass.\",\n",
        "#     \"Either way he is still the one paying most of the bills (until I finish my PhD), and people are okay with that so long as they view the relationship as monogamous. It could be some socially constructed reciprocity of man being breadwinner and woman homemaker or something more instinctual. I surrender that thought to you social scientists and will head back to the lab and to the simpler world of biochemistry.\",\n",
        "#     \"He is already six feet under for 6 years now.\"\n",
        "# ]\n",
        "\n",
        "# inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "# inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     outputs = model(**inputs)\n",
        "#     logits = outputs.logits\n",
        "#     predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# for sentence, prediction in zip(sentences, predictions):\n",
        "#     print(f\"Sentence: {sentence}\")\n",
        "#     print(f\"Prediction (class): {prediction.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Прогоним для анализа тот же семл, что смотрели для бейзлайна\n",
        "\n",
        "baseline_sample = pd.read_csv('/content/baseline_predictions_to_manual_check.csv')"
      ],
      "metadata": {
        "id": "0CqflIXbxYnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# sentences = test_df['utterance'].tolist()\n",
        "# true_labels = test_df['label']\n",
        "\n",
        "# 100 для анализа\n",
        "sentences = baseline_sample['utterance'].head(100).tolist()\n",
        "true_labels = baseline_sample['true_label'].head(100)\n",
        "\n",
        "# Токенизация\n",
        "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\", batch_size=8)  # уменьшите batch_size\n",
        "\n",
        "# Перемещение модели на GPU, если оно доступно\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "# Прогон тестовых данных через модель\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# Расчет F1-метрики для каждого класса отдельно\n",
        "f1_per_class = f1_score(true_labels, predictions.cpu().numpy(), average=None)\n",
        "\n",
        "# Печать F1 для каждого класса\n",
        "for i, f1 in enumerate(f1_per_class):\n",
        "    print(f\"Class {i}: F1 = {f1:.4f}\")\n",
        "\n",
        "for sentence, true_label, prediction in zip(sentences, true_labels, predictions):\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"True label: {true_label}, Prediction: {prediction.item()}\")"
      ],
      "metadata": {
        "id": "pfgOn-LqvgPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "1Iklk-Hyo3vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраним 100 примеров для ручного анализа\n",
        "\n",
        "import csv\n",
        "\n",
        "output_file = '/content/EUREKA_results_to_analyse.csv'  # Путь к файлу для сохранения\n",
        "with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Sentence', 'True label', 'Prediction'])  # Заголовки столбцов\n",
        "    for sentence, true_label, prediction in zip(sentences, true_labels, predictions):\n",
        "        writer.writerow([sentence, true_label, prediction.item()])\n",
        "\n",
        "print(f\"Results saved to {output_file}\")"
      ],
      "metadata": {
        "id": "GofvYFkOqLhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOaeKuRt3K52"
      },
      "outputs": [],
      "source": [
        "# Сохраним чекпоинт\n",
        "\n",
        "!zip -r eng_trained_model.zip \"/content/output_111/checkpoint-490\"\n",
        "\n",
        "from google.colab import files\n",
        "files.download('eng_trained_model.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFcSPthax33x"
      },
      "source": [
        "Используем обученную сохраненную модель для предсказаний на нашем датасете"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4ZWF1MRyaMO"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUjlGnStyU5l"
      },
      "outputs": [],
      "source": [
        "zip_path = \"PATH_TO_ZIP\" # путь к архиву\n",
        "extract_path = \"/content/output_111\"  # путь к папке для извлечения архива\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtIemCOiyppp"
      },
      "outputs": [],
      "source": [
        "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizerFast\n",
        "\n",
        "checkpoint_dir = \"/content/output_111/content/output_111/checkpoint-490\"\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(checkpoint_dir)\n",
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"FacebookAI/xlm-roberta-large\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "for i in range(0, len(test_df['utterance'].tolist()), batch_size):\n",
        "    batch = test_df['utterance'].tolist()[i:i + batch_size]\n",
        "    inputs = tokenizer(batch, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=-1).cpu().tolist()\n",
        "        predictions.extend(preds)\n",
        "\n",
        "for sentence, pred in zip(test_df['utterance'].tolist(), predictions):\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Prediction: {pred}\")"
      ],
      "metadata": {
        "id": "PZXvc38_omxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KI6QTxL_MfM"
      },
      "outputs": [],
      "source": [
        "# Оценка модели\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "y_pred = []\n",
        "for sentence, pred in zip(test_df['utterance'].tolist(), predictions):\n",
        "    y_pred.append(pred)\n",
        "\n",
        "y_true = test_df[\"label\"].tolist()\n",
        "\n",
        "# F1 по каждому классу\n",
        "print(classification_report(y_true, y_pred, target_names=[\"No euphemism\", \"Euphemism\"]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}