{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install unrar\n",
        "!pip install patool"
      ],
      "metadata": {
        "id": "FtKU2uT7bxnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import patoolib\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "XunAs5FwK3V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к RAR-архиву\n",
        "rar_file = '/content/all_annotated.rar'\n",
        "\n",
        "# Папочка для распаковки\n",
        "extract_folder = 'my_data_2'\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "patoolib.extract_archive(rar_file, outdir=extract_folder)"
      ],
      "metadata": {
        "id": "jrv8jAVMbGVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGXdVkZxJv5M"
      },
      "outputs": [],
      "source": [
        "# Папка с JSON-файлами\n",
        "folder_path = '/content/my_data_2/all_annotated'\n",
        "\n",
        "# Списки для хранения текстов с лейблами и без\n",
        "texts_with_euphemism = []\n",
        "texts_without_euphemism = []\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.json'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Чтение JSON-файла\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            data = json.load(file)\n",
        "\n",
        "            for item in data:\n",
        "                # Извлекаем текст\n",
        "                text = item.get('text', '')\n",
        "\n",
        "                # Проверка наличия лейбла <euphemism>\n",
        "                if '<euphemism>' in text:\n",
        "                    texts_with_euphemism.append({\n",
        "                        'filename': filename,\n",
        "                        'index': item.get('index', None),  # Сохраняем индекс\n",
        "                        'text': text\n",
        "                    })\n",
        "                else:\n",
        "                    texts_without_euphemism.append({\n",
        "                        'filename': filename,\n",
        "                        'index': item.get('index', None),\n",
        "                        'text': text\n",
        "                    })\n",
        "\n",
        "# Создание датафреймов\n",
        "df_with_euphemism = pd.DataFrame(texts_with_euphemism)\n",
        "df_without_euphemism = pd.DataFrame(texts_without_euphemism)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Тексты с лейблом <euphemism>:\")\n",
        "print(df_with_euphemism)"
      ],
      "metadata": {
        "id": "J58cBh3rdhla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_euphemism.to_csv('only_euphemism_dataset.csv')"
      ],
      "metadata": {
        "id": "nckhubjDdpxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nТексты без лейбла <euphemism>:\")\n",
        "print(df_without_euphemism)"
      ],
      "metadata": {
        "id": "4uGG-VMndjEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_without_euphemism.dropna()"
      ],
      "metadata": {
        "id": "9Fq2rMjg2U3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_without_euphemism)"
      ],
      "metadata": {
        "id": "ruVMHfiC2Ogs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Следующие ячейки используются после ручной проверки текстов с эвфемизмами"
      ],
      "metadata": {
        "id": "RyZG_6MScLJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем проверенный датасет с эвфемизмами\n",
        "\n",
        "euph_d = pd.read_csv('/content/only_euphemism_dataset.csv')\n",
        "euph_d = euph_d.dropna()"
      ],
      "metadata": {
        "id": "bmkv_blowGHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(euph_d)"
      ],
      "metadata": {
        "id": "6cwYuLrrzfiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(euph_d.isna().sum())"
      ],
      "metadata": {
        "id": "liIC99n90lBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Присваиваем текстам метки 1 (если в тексте есть эвфемизм) или 0 (если нет) и удаляем теги <euphemism>\n",
        "# Затем объединяем датасеты без эвфемизмов и проверенный датасет с эвфемизмами - получаем финальный датасет"
      ],
      "metadata": {
        "id": "dXxC6jWGtDJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаляет теги <euphemism> и </euphemism> из текста\n",
        "\n",
        "\n",
        "def remove_euphemism_tags(text):\n",
        "    if isinstance(text, str):  # Проверяем, является ли текст строкой\n",
        "        return re.sub(r'<euphemism>|</euphemism>', '', text)\n",
        "    return \"\"  # Возвращаем пустую строку для нестроковых значений"
      ],
      "metadata": {
        "id": "D2jtnSuhxtqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавляем метки\n",
        "euph_d['label'] = 1  # Тексты с эвфемизмами\n",
        "euph_d['utterance'] = euph_d['text'].apply(remove_euphemism_tags)\n",
        "euph_d.drop('text', axis=1, inplace=True)\n",
        "euph_d.drop('filename', axis=1, inplace=True)\n",
        "euph_d.drop('index', axis=1, inplace=True)\n",
        "euph_d.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "vOxw0B1ivil5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "euph_d"
      ],
      "metadata": {
        "id": "gq2FddSD3Bnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_without_euphemism['label'] = 0  # Тексты без эвфемизмов\n",
        "df_without_euphemism.drop('filename', axis=1, inplace=True)\n",
        "df_without_euphemism.drop('index', axis=1, inplace=True)\n",
        "df_without_euphemism.rename(columns={'text': 'utterance'}, inplace=True)"
      ],
      "metadata": {
        "id": "B-IzczHx3Kmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_without_euphemism"
      ],
      "metadata": {
        "id": "WDpUycQN35CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Объединяем датафреймы\n",
        "combined_df = pd.concat([euph_d, df_without_euphemism], ignore_index=True)\n",
        "\n",
        "# Вывод результата\n",
        "print(combined_df)"
      ],
      "metadata": {
        "id": "x38_r_Wg360U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.isna().sum())"
      ],
      "metadata": {
        "id": "u_QBoTiw15Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(combined_df)"
      ],
      "metadata": {
        "id": "cJDfbBVX1wpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.head())"
      ],
      "metadata": {
        "id": "bz_OGbk_17pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.to_csv('dataset_full.csv')"
      ],
      "metadata": {
        "id": "f5RBDRvswnQ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}